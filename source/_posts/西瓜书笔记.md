---
title: 机器学习笔记
layout: post
---
# 西瓜书笔记
### 目录
[toc]
***
<!-- more -->
### 第二章 模型评估与选择  
#### 评估方法
对数据集D产生训练集S和测试集T的方法：
- **留出法**
直接划分两个互斥的集合；划分要尽可能保持数据分布的一致性。
从采样的角度来看待数据集的划分过程，则保留类别比例的采样方式通常称为“分层采样”。
单次使用留出法得到的估计结果往往不够稳定可靠。一般要采用若干次随机划分、重复进行试验评估后取平均值作为留出法的评估结果。
常规做法是2/3~4/5的样本用于训练，剩余样本用于测试。
- **交叉验证法**
数据集划分为k个大小相似的互斥自己，每个子集从D中通过分层采样得到。 每次用k-1个子集的并集作为训练集，进行k次训练和测试，返回k次测试结果的均值。通常交叉验证又称为“k折交叉验证”k最常用的取值是10.
在划分为k个不同的子集时，要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值。
交叉验证的特例：留一法：D中包含m个样本，令k=m，每个子集只有一个样本，留一法中呗实际评估的模型与期望评估的用D训练处的模型很相似，所以结果更准确。
留一法的缺陷：当数据集比较大时，训练模型的计算开销非常大。
- **自助法**
前面两种方法（留出法、交叉验证法）实际评估模型使用的训练集比D小，留一法又计算复杂度太高，所以期待一个可以减少训练样本规模不同造成的影响，又高效的方法。
自助法（bootstrapping）：
对于含有m个样本的数据集D，每次有放回的取一个数据放在D'中，进行m次，这样得到训练集D'，D中会有36.8%的样本未出现在采样数据集D'中，用D\D'（未出现在D'中的数据）作为测试集。
这样，实际评估的和期望评估的都有m个样本，有约1/3的没在训练集中出现的样本用于测试。 这样的测试结果，亦称“包外估计”。
自助法的特点：
    1. 在数据集较小、难以有效划分训练/测试集时很有用，
    2. 能从初始数据中产生多个不同的训练集，对集成学习有很大好处；
    3. 产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用。
    
- 调参与最终模型
调参经常的做法是选定参数范围和步长。
调参往往很困难。
参数配置不同，学的的模型性能往往有明显差别。
模型评估与选择中用于评估测试的数据集成为“验证集”。
基于验证集上的性能来进行模型选择与调参。

#### 性能度量  
衡量模型泛化能力的评价标准就是性能度量。
什么样的模型是好的，不仅仅取决于算法和数据，还取决于任务需求。
回归任务最常用的性能度量是**均方误差**
- 错误率和精度
错误率是值错误的样本数占样本总数的比例，精度是指正确的样本数占比。错误率=1-精度。  
- 查准率（precision）、查全率(recall)
查准率：预测正为准的比上预测为正的；（挑出的瓜有多少是好瓜）
查全率：预测为正的准的比上实际为正的；（所有号瓜中有多少比例被挑出来了）
查准率和查全率是一对矛盾的度量。
根据预测结果排序，按顺序把样本作为正例进行预测，以查准率为纵轴、查全率为横轴做图，就得到了查准率-查全率曲线，建成P-R曲线。
若一个学习期的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者。
- 平衡点（BEP） 就是一个综合考虑查准率、查全率的性能度量。它是“查准率=查全率”时的取值。平衡点越大，性能越优。
- F1度量 平衡点还是简化了点。在一些应用中，对查准率和查全率的重视程度不同。
F1度量的一般形式：
> 公式太麻烦了，这里先不输入。后面可以学一学LaTeX语法之后再输入。  

- ROC与AUC
首先明白，AUC就是ROC曲线下面的面积，可用来比较学习器的性能。
ROC曲线与P-R曲线不同的是，ROC曲线的纵轴是“真正确率”（TPR），横轴是“假正确率”（FPR）

- 代价敏感错误率与代价曲线
不同类型的错误所造成的后果不同。为错误赋予“非均等代价（unequal cost）”
在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，而“代价曲线（cost curve）”可以达到该目的。
代价曲线图的横轴是取值为[0,1]的正例概率代价，纵轴是取值为[0,1]的归一化代价。
#### 比较检验
机器学习中性能比较这件事比我们想象的要复杂得多。涉及几个重要因素：
1. 我们希望比较的是泛化性能，然而通过实验评估方法我们获得的是在测试集上的性能，两者未必一致；
2. 测试集性能与测试集选择关系很大；
3. 很多机器学习算法本身具有一定的随机性，相同参数运行多次，结果也会有不同。

统计假设检验（hypothesis test）在学习器性能比较上提供了重要依据。基于假设检验结果，可推断出，在测试集上效果好，泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。
接下来，默认以错误率为性能度量。
- 假设检验

- 交叉验证t检验

- McNemar检验

- Friedman检验与Nemenyi后续检验




### 第三章 线性模型
#### 线性回归
- 对于离散属性，若属性值间存在“序”关系，可通过连续化将其转化为连续值，例如身高取值{高，矮}可转化为{1.0,0.0}，三值属性“高度”的取值“高”“中”“低”可转化为k维向量，例如属性“瓜类”的取值“西瓜”“南瓜”“黄瓜”取值可转化为（，0,1），（0,1,0），（1,0,0）
> 若将无序属性连续化，则会不恰当地引入序关系，对后续处理如距离计算等造成误导。

均方误差是回归任务中最常用的性能度量，具有很好的几何意义，对应了常用的欧几里得距离，建成欧氏距离。
基于均方误差最小化来进行模型求解的方法称为最小二乘法(least square method)。

对数线性模型:
```math
lny = w^T+b
```

广义线性模型:
```math
y = g^{-1} (w^Tx + b)
```
对数线性回归是广义线性回归的特例。

#### 对数几率回归